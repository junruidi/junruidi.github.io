confusionMatrix(table(as.numeric(pred_class),y))
y = data$fac2
cv.logistic <- cv.glmnet(x, y=y, alpha=1,family = "binomial",type.measure = "class")
coef(cv.logistic,s = "lambda.min")
pred_class = predict(cv.logistic, newx = x, s = "lambda.min",type = "class")
confusionMatrix(table(as.numeric(pred_class),y))
y = data$fac2
cv.logistic <- cv.glmnet(x, y=y, alpha=1,family = "binomial",type.measure = "class")
coef(cv.logistic,s = "lambda.min")
pred_class = predict(cv.logistic, newx = x, s = "lambda.min",type = "class")
confusionMatrix(table(as.numeric(pred_class),y))
y = data$fac2
cv.logistic <- cv.glmnet(x, y=y, alpha=1,family = "binomial",type.measure = "class")
coef(cv.logistic,s = "lambda.min")
pred_class = predict(cv.logistic, newx = x, s = "lambda.min",type = "class")
confusionMatrix(table(as.numeric(pred_class),y))
y = data$fac2
cv.logistic <- cv.glmnet(x, y=y, alpha=1,family = "binomial",type.measure = "class")
coef(cv.logistic,s = "lambda.min")
pred_class = predict(cv.logistic, newx = x, s = "lambda.min",type = "class")
confusionMatrix(table(as.numeric(pred_class),y))
y = data$fac2
cv.logistic <- cv.glmnet(x, y=y, alpha=1,family = "binomial",type.measure = "class")
coef(cv.logistic,s = "lambda.min")
pred_class = predict(cv.logistic, newx = x, s = "lambda.min",type = "class")
confusionMatrix(table(as.numeric(pred_class),y))
y = data$fac2
cv.logistic <- cv.glmnet(x, y=y, alpha=1,family = "binomial",type.measure = "class")
coef(cv.logistic,s = "lambda.min")
pred_class = predict(cv.logistic, newx = x, s = "lambda.min",type = "class")
confusionMatrix(table(as.numeric(pred_class),y))
y = data$fac3
cv.logistic <- cv.glmnet(x, y=y, alpha=1,family = "binomial",type.measure = "class",)
coef(cv.logistic,s = "lambda.min")
pred_class = predict(cv.logistic, newx = x, s = "lambda.min",type = "class")
confusionMatrix(table(as.numeric(pred_class),y))
y = data$fac3
cv.logistic <- cv.glmnet(x, y=y, alpha=1,family = "binomial",type.measure = "class",)
coef(cv.logistic,s = "lambda.min")
pred_class = predict(cv.logistic, newx = x, s = "lambda.min",type = "class")
confusionMatrix(table(as.numeric(pred_class),y))
y = data$fac3
cv.logistic <- cv.glmnet(x, y=y, alpha=1,family = "binomial",type.measure = "class",)
coef(cv.logistic,s = "lambda.min")
pred_class = predict(cv.logistic, newx = x, s = "lambda.min",type = "class")
confusionMatrix(table(as.numeric(pred_class),y))
y = data$fac3
cv.logistic <- cv.glmnet(x, y=y, alpha=1,family = "binomial",type.measure = "class")
coef(cv.logistic,s = "lambda.min")
pred_class = predict(cv.logistic, newx = x, s = "lambda.min",type = "class")
confusionMatrix(table(as.numeric(pred_class),y))
#1. assemble the data
rm(list = ls())
load("~/Dropbox/Junrui Di/PACS Modeling/outcome/outcome.rda")
load("~/Dropbox/Junrui Di/PACS Modeling/Continuous Monitor/data clean/cleandata.rda")
load("~/Dropbox/Junrui Di/PACS Modeling/Continuous Monitor/data clean/demo.rda")
newor = data.frame(ID = time$ID, or = time$or, fasc = outcome$fac1)
neworid = newor$ID[which(newor$or == 1 & newor$fasc !=1)]
varb = subset(continue, Varname %in% c("pain","bpLO","bpUP","vascDPA"))
varbb = varb[,-c(1:2)]
rmean = rowMeans(varbb,na.rm = T)
rsd = NULL
for(i in 1:nrow(varbb)){
x = as.numeric(varbb[i,])
rsd = c(rsd, sd(x,na.rm = T))
}
rn = NULL
for(i in 1:nrow(varbb)){
x = as.numeric(varbb[i,])
rn = c(rn, sum(!is.na(x)))
}
varb_meansd = data.frame(ID = varb$ID, Varname = varb$Varname, mean = rmean, std = rsd,num = rn)
library(reshape)
varb_meansb2 = reshape(varb_meansd, idvar = "ID",timevar = "Varname",direction = "wide")
listcol = seq(2,ncol(varb_meansb2),3)
for(l in 1:length(listcol)){
l.col = listcol[l]
print(paste(names(varb_meansb2)[l.col],sum(is.na(varb_meansb2[,l.col])),sep = "-"))
}
varb_meansd_processed = varb_meansb2[-which(is.na(varb_meansb2$mean.pain) | is.na(varb_meansb2$mean.vascDPA) | is.na(varb_meansb2$mean.bpLO) | is.na(varb_meansb2$mean.bpUP)),]
#167 subect
#switch NA std to 0
varb_meansd_processed[is.na(varb_meansd_processed)] = 0
varb_meansd_processed$or = ifelse(varb_meansd_processed$ID %in% neworid,1,0)
data = merge(x = varb_meansd_processed, y = demodat)
data = merge(x = data, y = outcome,all.x = T)
idremove = paste("PAC",sep = "-",c(1560,2797,1692,1606,1648,1650,1705,5718,5798))
data = data[-which(data$ID %in% idremove),]
library(glmnet)
library(caret)
x = data[,c(2:19)]
x = model.matrix(~.,x)
y = as.factor(ifelse(data$group2 == "High",1,0))
rf_model = train(x = x, y = y, method="rf",
trControl=trainControl(method="cv",number=10),
prox=TRUE)
y = as.factor(ifelse(data$group2 == "High",1,0))
rf_model = train(x = x, y = y, method="rf",
trControl=trainControl(method="cv",number=10),
prox=TRUE)
print(rf_model)
print(rf_model$finalModel)
y = as.factor(data$fac1)
rf_model = train(x = x, y = y, method="rf",
trControl=trainControl(method="cv",number=10),
prox=TRUE)
print(rf_model)
print(rf_model$finalModel)
y = as.factor(data$fac2)
rf_model = train(x = x, y = y, method="rf",
trControl=trainControl(method="cv",number=10),
prox=TRUE)
print(rf_model)
print(rf_model$finalModel)
y = as.factor(data$fac2)
rf_model = train(x = x, y = y, method="rf",
trControl=trainControl(method="cv",number=10),
prox=TRUE)
print(rf_model)
print(rf_model$finalModel)
y = as.factor(data$fac2)
rf_model = train(x = x, y = y, method="rf",
trControl=trainControl(method="cv",number=10),
prox=TRUE)
print(rf_model)
print(rf_model$finalModel)
y = as.factor(data$fac2)
rf_model = train(x = x, y = y, method="rf",
trControl=trainControl(method="cv",number=10),
prox=TRUE)
print(rf_model)
print(rf_model$finalModel)
y = as.factor(data$fac3)
rf_model = train(x = x, y = y, method="rf",
trControl=trainControl(method="cv",number=10),
prox=TRUE)
print(rf_model)
print(rf_model$finalModel)
y = as.factor(data$fac3)
rf_model = train(x = x, y = y, method="rf",
trControl=trainControl(method="cv",number=10),
prox=TRUE)
print(rf_model)
print(rf_model$finalModel)
y = as.factor(data$fac3)
rf_model = train(x = x, y = y, method="rf",
trControl=trainControl(method="cv",number=10),
prox=TRUE)
print(rf_model)
print(rf_model$finalModel)
y = as.factor(data$fac3)
rf_model = train(x = x, y = y, method="rf",
trControl=trainControl(method="cv",number=10),
prox=TRUE)
print(rf_model)
print(rf_model$finalModel)
varImp(rf_model)
#1. assemble the data
rm(list = ls())
load("~/Dropbox/Junrui Di/PACS Modeling/outcome/outcome.rda")
load("~/Dropbox/Junrui Di/PACS Modeling/Continuous Monitor/data clean/cleandata.rda")
load("~/Dropbox/Junrui Di/PACS Modeling/Continuous Monitor/data clean/demo.rda")
newor = data.frame(ID = time$ID, or = time$or, fasc = outcome$fac1)
neworid = newor$ID[which(newor$or == 1 & newor$fasc !=1)]
varb = subset(continue, Varname %in% c("pain","bpLO","bpUP","vascDPA"))
varbb = varb[,-c(1:2)]
rmean = rowMeans(varbb,na.rm = T)
rsd = NULL
for(i in 1:nrow(varbb)){
x = as.numeric(varbb[i,])
rsd = c(rsd, sd(x,na.rm = T))
}
rn = NULL
for(i in 1:nrow(varbb)){
x = as.numeric(varbb[i,])
rn = c(rn, sum(!is.na(x)))
}
varb_meansd = data.frame(ID = varb$ID, Varname = varb$Varname, mean = rmean, std = rsd,num = rn)
library(reshape)
varb_meansb2 = reshape(varb_meansd, idvar = "ID",timevar = "Varname",direction = "wide")
listcol = seq(2,ncol(varb_meansb2),3)
for(l in 1:length(listcol)){
l.col = listcol[l]
print(paste(names(varb_meansb2)[l.col],sum(is.na(varb_meansb2[,l.col])),sep = "-"))
}
varb_meansd_processed = varb_meansb2[-which(is.na(varb_meansb2$mean.pain) | is.na(varb_meansb2$mean.vascDPA) | is.na(varb_meansb2$mean.bpLO) | is.na(varb_meansb2$mean.bpUP)),]
#167 subect
#switch NA std to 0
varb_meansd_processed[is.na(varb_meansd_processed)] = 0
varb_meansd_processed$or = ifelse(varb_meansd_processed$ID %in% neworid,1,0)
data = merge(x = varb_meansd_processed, y = demodat)
data = merge(x = data, y = outcome,all.x = T)
idremove = paste("PAC",sep = "-",c(1560,2797,1692,1606,1648,1650,1705,5718,5798))
data = data[-which(data$ID %in% idremove),]
library(glmnet)
library(caret)
x = data[,c(2:19)]
x = model.matrix(~.,x)
#2. outcome 1_likelihood
y = as.factor(ifelse(data$group2 == "High",1,0))
rf_model = train(x = x, y = y, method="rf",
trControl=trainControl(method="cv",number=10),
prox=TRUE)
print(rf_model)
print(rf_model$finalModel)
varImp(rf_model)
y = as.factor(data$fac1)
rf_model = train(x = x, y = y, method="rf",
trControl=trainControl(method="cv",number=10),
prox=TRUE)
print(rf_model)
print(rf_model$finalModel)
varImp(rf_model)
y = as.factor(data$fac2)
rf_model = train(x = x, y = y, method="rf",
trControl=trainControl(method="cv",number=10),
prox=TRUE)
print(rf_model)
print(rf_model$finalModel)
varImp(rf_model)
y = as.factor(data$fac3)
rf_model = train(x = x, y = y, method="rf",
trControl=trainControl(method="cv",number=10),
prox=TRUE)
print(rf_model)
print(rf_model$finalModel)
varImp(rf_model)
View(data)
install.packages("ManifoldOptim")
1e-300
x = 1e-300
y = 1e-3
x
y
x>7
x>y
x==y
#########################################
##      aggregate Survival Models      ##
#########################################
# 1. load in data ---------------------------------------------------------
rm(list = ls())
load("~/Dropbox/Junrui Di/fragmentation/Review AJE/aggregate/data/analysis/surv50.rda")
library(survey)
library(survival)
library(simPH)
library(nhanesaccel)
surv = subset(surv50,select = -c(RIDAGEMN,RIAGENDR,RIDRETH1,DMDEDUC,DIQ010,MCQ160B,MCQ160C,MCQ160F,MCQ220,SMQ020,Alcohol,DrinksPerWeek,
DrinksPerWeek,DrinkStatus, SmokeCigs))
#check for missing
for(i in 1:ncol(surv)){
print(names(surv)[i])
print(sum(is.na(surv[,i])))
}
#28 missing BMI
surv = surv[-which(surv$permth_exm<=12 & surv$mortstat == 1),]
# 2. Remove missing values and create first survey object -----------------
survv = na.omit(surv)
survv$survyr = survv$permth_exm/12
include.column = which(names(survv)=="include")
c1 = subset(survv,yr==34)
d1 = subset(survv,yr==56)
c2 = nhanes.accel.reweight(acceldata = c1, wave = 1, seqn.column = 1,
include.column = include.column)
d2 = nhanes.accel.reweight(acceldata = d1, wave = 2, seqn.column = 1,
include.column = include.column)
survv$wt4yr = c(c2$wtmec2yr_adj/2,d2$wtmec2yr_adj/2)
#create survey object
svydata = svydesign(id=~SDMVPSU,
strat=~SDMVSTRA,
weight=~wt4yr,
nest=TRUE,
data=survv)
#save(survv,file = "~/Dropbox/Junrui Di/fragmentation/Review AJE/aggregate/data/analysis/naomit.rda")
# 3. caluclate z scores and create the second survey subjects -------------
names(survv)[2:21] = paste0("z.",names(survv)[2:21])
for (i in 2:21){
survv[,i] = (survv[,i]-svymean(~survv[,i],svydata))/sqrt(svyvar(~survv[,i],svydata))
}
ori.measurement = surv[,1:21]
survv = merge(x=ori.measurement,y=survv)
include.column = which(names(survv)=="include")
c1 = subset(survv,yr==34)
d1 = subset(survv,yr==56)
c2 = nhanes.accel.reweight(acceldata = c1, wave = 1, seqn.column = 1,
include.column = include.column)
d2 = nhanes.accel.reweight(acceldata = d1, wave = 2, seqn.column = 1,
include.column = include.column)
survv$wt4yr = c(c2$wtmec2yr_adj/2,d2$wtmec2yr_adj/2)
#create survey object
svydata = svydesign(id=~SDMVPSU,
strat=~SDMVSTRA,
weight=~wt4yr,
nest=TRUE,
data=survv)
#3333 subjects
# 4. Survival Modeling ----------------------------------------------------
# 4.1 Base Modesl ---------------------------------------------------------
cox.ph.baseact = svycoxph(Surv(permth_exm/12,mortstat) ~ age + Male  + BMXBMI+
diabetes + CHF + stroke + cancer + CHD+
MobilityProblem + Mexican + HispanicOther + Black + OtherRace +
LessThanHS + HighSchool + MissingEduc +CurrentSmoker + FormerSmoker +
FormerDrinker + ModerateDrinker+ HeavyDrinker+ MissingAlcohol+aveact,design=svydata)
summary(cox.ph.baseact)
cox.ph.bfir= svycoxph(Surv(permth_exm/12,mortstat) ~ age + Male  + BMXBMI+
diabetes + CHF + stroke + cancer + CHD+
MobilityProblem + Mexican + HispanicOther + Black + OtherRace +
LessThanHS + HighSchool + MissingEduc +CurrentSmoker + FormerSmoker +
FormerDrinker + ModerateDrinker+ HeavyDrinker+ MissingAlcohol+
avesed+
z.BFI.r,design=svydata)
summary(cox.ph.bfir)
cox.ph.bfia= svycoxph(Surv(permth_exm/12,mortstat) ~ age + Male  + BMXBMI+
diabetes + CHF + stroke + cancer + CHD+
MobilityProblem + Mexican + HispanicOther + Black + OtherRace +
LessThanHS + HighSchool + MissingEduc +CurrentSmoker + FormerSmoker +
FormerDrinker + ModerateDrinker+ HeavyDrinker+ MissingAlcohol+
z.BFI.a,design=svydata)
summary(cox.ph.bfia)
cox.ph.ahfa1 = svycoxph(Surv(permth_exm/12,mortstat) ~ age + Male  + BMXBMI+
diabetes + CHF + stroke + cancer + CHD+
MobilityProblem + Mexican + HispanicOther + Black + OtherRace +
LessThanHS + HighSchool + MissingEduc +CurrentSmoker + FormerSmoker +
FormerDrinker + ModerateDrinker+ HeavyDrinker+ MissingAlcohol+
z.ahfa1,design=svydata)
summary(cox.ph.ahfa1)
#########################################
##      aggregate Survival Models      ##
#########################################
# 1. load in data ---------------------------------------------------------
rm(list = ls())
load("~/Dropbox/Junrui Di/fragmentation/Review AJE/aggregate/data/analysis/surv50.rda")
library(survey)
library(survival)
library(simPH)
library(nhanesaccel)
surv = subset(surv50,select = -c(RIDAGEMN,RIAGENDR,RIDRETH1,DMDEDUC,DIQ010,MCQ160B,MCQ160C,MCQ160F,MCQ220,SMQ020,Alcohol,DrinksPerWeek,
DrinksPerWeek,DrinkStatus, SmokeCigs))
#check for missing
for(i in 1:ncol(surv)){
print(names(surv)[i])
print(sum(is.na(surv[,i])))
}
#28 missing BMI
surv = surv[-which(surv$permth_exm<=12 & surv$mortstat == 1),]
# 2. Remove missing values and create first survey object -----------------
survv = na.omit(surv)
survv$survyr = survv$permth_exm/12
include.column = which(names(survv)=="include")
c1 = subset(survv,yr==34)
d1 = subset(survv,yr==56)
c2 = nhanes.accel.reweight(acceldata = c1, wave = 1, seqn.column = 1,
include.column = include.column)
d2 = nhanes.accel.reweight(acceldata = d1, wave = 2, seqn.column = 1,
include.column = include.column)
survv$wt4yr = c(c2$wtmec2yr_adj/2,d2$wtmec2yr_adj/2)
#create survey object
svydata = svydesign(id=~SDMVPSU,
strat=~SDMVSTRA,
weight=~wt4yr,
nest=TRUE,
data=survv)
#save(survv,file = "~/Dropbox/Junrui Di/fragmentation/Review AJE/aggregate/data/analysis/naomit.rda")
# 3. caluclate z scores and create the second survey subjects -------------
names(survv)[2:21] = paste0("z.",names(survv)[2:21])
for (i in 2:21){
survv[,i] = (survv[,i]-svymean(~survv[,i],svydata))/sqrt(svyvar(~survv[,i],svydata))
}
ori.measurement = surv[,1:21]
survv = merge(x=ori.measurement,y=survv)
include.column = which(names(survv)=="include")
c1 = subset(survv,yr==34)
d1 = subset(survv,yr==56)
c2 = nhanes.accel.reweight(acceldata = c1, wave = 1, seqn.column = 1,
include.column = include.column)
d2 = nhanes.accel.reweight(acceldata = d1, wave = 2, seqn.column = 1,
include.column = include.column)
survv$wt4yr = c(c2$wtmec2yr_adj/2,d2$wtmec2yr_adj/2)
#create survey object
svydata = svydesign(id=~SDMVPSU,
strat=~SDMVSTRA,
weight=~wt4yr,
nest=TRUE,
data=survv)
#3333 subjects
# 4. Survival Modeling ----------------------------------------------------
# 4.1 Base Modesl ---------
cox.ph.ginir = svycoxph(Surv(permth_exm/12,mortstat) ~ age + Male  + BMXBMI+
diabetes + CHF + stroke + cancer + CHD+
MobilityProblem + Mexican + HispanicOther + Black + OtherRace +
LessThanHS + HighSchool + MissingEduc +CurrentSmoker + FormerSmoker +
FormerDrinker + ModerateDrinker+ HeavyDrinker+ MissingAlcohol+
z.gini.r,design=svydata)
summary(cox.ph.ginir)
cox.ph.ginia = svycoxph(Surv(permth_exm/12,mortstat) ~ age + Male  + BMXBMI+
diabetes + CHF + stroke + cancer + CHD+
MobilityProblem + Mexican + HispanicOther + Black + OtherRace +
LessThanHS + HighSchool + MissingEduc +CurrentSmoker + FormerSmoker +
FormerDrinker + ModerateDrinker+ HeavyDrinker+ MissingAlcohol+
z.gini.a,design=svydata)
summary(cox.ph.ginia)
cox.ph.arest1= svycoxph(Surv(permth_exm/12,mortstat) ~ age + Male  + BMXBMI+
diabetes + CHF + stroke + cancer + CHD+
MobilityProblem + Mexican + HispanicOther + Black + OtherRace +
LessThanHS + HighSchool + MissingEduc +CurrentSmoker + FormerSmoker +
FormerDrinker + ModerateDrinker+ HeavyDrinker+ MissingAlcohol+
avesed+
z.arest1,design=svydata)
summary(cox.ph.arest1)
#Set our working directory.
#This helps avoid confusion if our working directory is
#not our site because of other projects we were
#working on at the time.
setwd("~/Dropbox/web/junruidi.github.io/")
#render your sweet site.
rmarkdown::render_site()
# git add -A
# git commit -m "2nd commit"
#Set our working directory.
#This helps avoid confusion if our working directory is
#not our site because of other projects we were
#working on at the time.
setwd("~/Dropbox/web/junruidi.github.io/")
#render your sweet site.
rmarkdown::render_site()
# git add -A
# git commit -m "2nd commit"
# git push origin master
rmarkdown::render_site()
#Set our working directory.
#This helps avoid confusion if our working directory is
#not our site because of other projects we were
#working on at the time.
setwd("~/Dropbox/web/junruidi.github.io/")
#render your sweet site.
rmarkdown::render_site()
# git add -A
#Set our working directory.
#This helps avoid confusion if our working directory is
#not our site because of other projects we were
#working on at the time.
setwd("~/Dropbox/web/junruidi.github.io/")
#render your sweet site.
rmarkdown::render_site()
# git add -A
#Set our working directory.
#This helps avoid confusion if our working directory is
#not our site because of other projects we were
#working on at the time.
setwd("~/Dropbox/web/junruidi.github.io/")
#render your sweet site.
rmarkdown::render_site()
# git add -A
# git commit -m "2nd commit"
# git push origin master
#Set our working directory.
#This helps avoid confusion if our working directory is
#not our site because of other projects we were
#working on at the time.
setwd("~/Dropbox/web/junruidi.github.io/")
#render your sweet site.
rmarkdown::render_site()
# git add -A
# git commit -m "2nd commit"
# git push origin master
#Set our working directory.
#This helps avoid confusion if our working directory is
#not our site because of other projects we were
#working on at the time.
setwd("~/Dropbox/web/junruidi.github.io/")
#render your sweet site.
rmarkdown::render_site()
#Set our working directory.
#This helps avoid confusion if our working directory is
#not our site because of other projects we were
#working on at the time.
setwd("~/Dropbox/web/junruidi.github.io/")
#render your sweet site.
rmarkdown::render_site()
# git add -A
# git commit -m "2nd commit"
# git push origin master
#Set our working directory.
#This helps avoid confusion if our working directory is
#not our site because of other projects we were
#working on at the time.
setwd("~/Dropbox/web/junruidi.github.io/")
#render your sweet site.
rmarkdown::render_site()
# git add -A
# git commit -m "2nd commit"
# git push origin master
#Set our working directory.
#This helps avoid confusion if our working directory is
#not our site because of other projects we were
#working on at the time.
setwd("~/Dropbox/web/junruidi.github.io/")
#render your sweet site.
rmarkdown::render_site()
# git add -A
# git commit -m "2nd commit"
# git push origin master
#Set our working directory.
#This helps avoid confusion if our working directory is
#not our site because of other projects we were
#working on at the time.
setwd("~/Dropbox/web/junruidi.github.io/")
#render your sweet site.
rmarkdown::render_site()
# git add -A
# git commit -m "2nd commit"
# git push origin master
