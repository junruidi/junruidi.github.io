import numpy as np
def vectorize_sequences(sequences, dimension=10000):
results = np.zeros((len(sequences), dimension))
for i, sequence in enumerate(sequences):
results[i, sequence] = 1.
return results
x_train = vectorize_sequences(train_data)
x_test = vectorize_sequences(test_data)
def to_one_hot(labels, dimension=46):
results = np.zeros((len(labels), dimension))
for i, label in enumerate(labels):
results[i, label] = 1.
return results
one_hot_train_labels = to_one_hot(train_labels)
one_hot_test_labels = to_one_hot(test_labels)
def to_one_hot(labels, dimension=46):
results = np.zeros((len(labels), dimension))
for i, label in enumerate(labels):
results[i, label] = 1.
return results
one_hot_train_labels = to_one_hot(train_labels)
one_hot_test_labels = to_one_hot(test_labels)
one_hot_test_labels
from keras.utils.np_utils import to_categorical
one_hot_train_labels = to_categorical(train_labels)
one_hot_test_labels = to_categorical(test_labels)
from keras import models
from keras import layers
model = models.Sequential()
model.add(layers.Dense(64, activation='relu', input_shape=(10000,)))
model.add(layers.Dense(64, activation='relu'))
model.add(layers.Dense(46, activation='softmax'))
from keras import models
from keras import layers
model = models.Sequential()
model.add(layers.Dense(64, activation='relu', input_shape=(10000,)))
model.add(layers.Dense(64, activation='relu'))
model.add(layers.Dense(46, activation='softmax'))
model.compile(optimizer='rmsprop',loss='categorical_crossentropy',metrics=['accuracy'])
x_val = x_train[:1000]
partial_x_train = x_train[1000:]
y_val = one_hot_train_labels[:1000]
partial_y_train = one_hot_train_labels[1000:]
history = model.fit(partial_x_train,
partial_y_train,
epochs=20,
batch_size=512,
validation_data=(x_val, y_val))
import matplotlib.pyplot as plt
loss = history.history['loss']
val_loss = history.history['val_loss']
epochs = range(1, len(loss) + 1)
plt.plot(epochs, loss, 'bo', label='Training loss')
plt.plot(epochs, val_loss, 'b', label='Validation loss')
plt.title('Training and validation loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.show()
import matplotlib.pyplot as plt
pip install matplotlib
librar
exit()
exit
library(reticulate)
matplotlib <- import("matplotlib")
use_python()
?use_python
uuse_python("C:/Users/Junrui/Anaconda3/python.exe")
use_python("C:/Users/Junrui/Anaconda3/python.exe")
matplotlib <- import("matplotlib")
matplotlib$use("Agg", force = TRUE)
matplotlib <- import("matplotlib")
library(reticulate)
use_condaenv()
?use_condaenv
use_condaenv(condaenv = NULL, conda = "auto", required = T)
reticulate::repl_python()
exit
?reticulate::repl_python
reticulate::repl_python()
import matplotlib.pyplot as plt
exit()
exti
library(reticulate)
use_condaenv() # Change accordingly to your Python version
matplotlib <- import("matplotlib")
matplotlib$use("Agg", force = TRUE)
exit
reticulate::repl_python()
library(reticulate)
use_condaenv() # Change accordingly to your Python version
matplotlib <- import("matplotlib")
matplotlib$use("Agg", force = TRUE)
exit
library(x)
library(reticulate)
use_condaenv()
matplotlib <- import("matplotlib")
matplotlib$use("Agg", force = TRUE)
reticulate::repl_python()
import pandas as pd
quit
reticulate::repl_python()
import pandas as pd
import numpy as np
s = pd.Series([1,3,5,6,8])
exit
install.packages("reticulate")
install.packages("reticulate")
reticulate::repl_python()
import pandas as pd
import numpy as np
s = pd.Series([1,3,5,6,8])
exit
library(reticulate)
use_virtualenv("r-reticulate")
use_condaenv()
reticulate::repl_python()
import pandas as pd
import numpy as np
exit
py_install("pandas")
reticulate::repl_python()
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
exit
py_install("matplotlib")
reticulate::repl_python()
import matplotlib.pyplot as plt
from keras.datasets import reuters
(train_data, train_labels), (test_data, test_labels) = reuters.load_data(num_words=10000)
import numpy as np
def vectorize_sequences(sequences, dimension=10000):
results = np.zeros((len(sequences), dimension))
for i, sequence in enumerate(sequences):
results[i, sequence] = 1.
return results
x_train = vectorize_sequences(train_data)
x_test = vectorize_sequences(test_data)
from keras.utils.np_utils import to_categorical
one_hot_train_labels = to_categorical(train_labels)
one_hot_test_labels = to_categorical(test_labels)
from keras import models
from keras import layers
model = models.Sequential()
model.add(layers.Dense(64, activation='relu', input_shape=(10000,)))
model.add(layers.Dense(64, activation='relu'))
model.add(layers.Dense(46, activation='softmax'))
model.compile(optimizer='rmsprop',loss='categorical_crossentropy',metrics=['accuracy'])
x_val = x_train[:1000]
partial_x_train = x_train[1000:]
y_val = one_hot_train_labels[:1000]
partial_y_train = one_hot_train_labels[1000:]
history = model.fit(partial_x_train,
partial_y_train,
epochs=20,
batch_size=512,
validation_data=(x_val, y_val))
import matplotlib.pyplot as plt
loss = history.history['loss']
val_loss = history.history['val_loss']
epochs = range(1, len(loss) + 1)
plt.plot(epochs, loss, 'bo', label='Training loss')
plt.plot(epochs, val_loss, 'b', label='Validation loss')
plt.title('Training and validation loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.show()
quit
library(reticulate)
use_python("C:/Users/Junrui/Anaconda3/python.exe")
library(reticulate)
use_python("C:/Users/Junrui/Anaconda3/python.exe")
use_virtualenv("r-reticulate")
reticulate::repl_python()
from keras.datasets import reuters
(train_data, train_labels), (test_data, test_labels) = reuters.load_data(num_words=10000)
import numpy as np
def vectorize_sequences(sequences, dimension=10000):
results = np.zeros((len(sequences), dimension))
for i, sequence in enumerate(sequences):
results[i, sequence] = 1.
return results
x_train = vectorize_sequences(train_data)
x_test = vectorize_sequences(test_data)
from keras.utils.np_utils import to_categorical
one_hot_train_labels = to_categorical(train_labels)
one_hot_test_labels = to_categorical(test_labels)
from keras import models
from keras import layers
model = models.Sequential()
model.add(layers.Dense(64, activation='relu', input_shape=(10000,)))
model.add(layers.Dense(64, activation='relu'))
model.add(layers.Dense(46, activation='softmax'))
model.compile(optimizer='rmsprop',loss='categorical_crossentropy',metrics=['accuracy'])
x_val = x_train[:1000]
partial_x_train = x_train[1000:]
y_val = one_hot_train_labels[:1000]
partial_y_train = one_hot_train_labels[1000:]
history = model.fit(partial_x_train,
partial_y_train,
epochs=20,
batch_size=512,
validation_data=(x_val, y_val))
import matplotlib.pyplot as plt
loss = history.history['loss']
val_loss = history.history['val_loss']
epochs = range(1, len(loss) + 1)
plt.plot(epochs, loss, 'bo', label='Training loss')
plt.plot(epochs, val_loss, 'b', label='Validation loss')
plt.title('Training and validation loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.show()
quit
library(reticulate)
use_python("C:/Users/Junrui/Anaconda3/python.exe")
reticulate::repl_python()
from keras.datasets import reuters
(train_data, train_labels), (test_data, test_labels) = reuters.load_data(num_words=10000)
import numpy as np
def vectorize_sequences(sequences, dimension=10000):
results = np.zeros((len(sequences), dimension))
for i, sequence in enumerate(sequences):
results[i, sequence] = 1.
return results
x_train = vectorize_sequences(train_data)
x_test = vectorize_sequences(test_data)
from keras.utils.np_utils import to_categorical
one_hot_train_labels = to_categorical(train_labels)
one_hot_test_labels = to_categorical(test_labels)
from keras import models
from keras import layers
model = models.Sequential()
model.add(layers.Dense(64, activation='relu', input_shape=(10000,)))
model.add(layers.Dense(64, activation='relu'))
model.add(layers.Dense(46, activation='softmax'))
model.compile(optimizer='rmsprop',loss='categorical_crossentropy',metrics=['accuracy'])
x_val = x_train[:1000]
partial_x_train = x_train[1000:]
y_val = one_hot_train_labels[:1000]
partial_y_train = one_hot_train_labels[1000:]
history = model.fit(partial_x_train,
partial_y_train,
epochs=20,
batch_size=512,
validation_data=(x_val, y_val))
library(reticulate)
use_python(python = "C:/Users/Junrui/Anaconda3/python.exe")
reticulate::repl_python()
from keras.datasets import reuters
(train_data, train_labels), (test_data, test_labels) = reuters.load_data(num_words=10000)
import numpy as np
def vectorize_sequences(sequences, dimension=10000):
results = np.zeros((len(sequences), dimension))
for i, sequence in enumerate(sequences):
results[i, sequence] = 1.
return results
x_train = vectorize_sequences(train_data)
x_test = vectorize_sequences(test_data)
from keras.utils.np_utils import to_categorical
one_hot_train_labels = to_categorical(train_labels)
one_hot_test_labels = to_categorical(test_labels)
from keras import models
from keras import layers
model = models.Sequential()
model.add(layers.Dense(64, activation='relu', input_shape=(10000,)))
model.add(layers.Dense(64, activation='relu'))
model.add(layers.Dense(46, activation='softmax'))
model.compile(optimizer='rmsprop',loss='categorical_crossentropy',metrics=['accuracy'])
x_val = x_train[:1000]
partial_x_train = x_train[1000:]
y_val = one_hot_train_labels[:1000]
partial_y_train = one_hot_train_labels[1000:]
history = model.fit(partial_x_train,
partial_y_train,
epochs=20,
batch_size=512,
validation_data=(x_val, y_val))
import matplotlib.pyplot as plt
loss = history.history['loss']
val_loss = history.history['val_loss']
epochs = range(1, len(loss) + 1)
plt.plot(epochs, loss, 'bo', label='Training loss')
plt.plot(epochs, val_loss, 'b', label='Validation loss')
plt.title('Training and validation loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.show()
quit
library(reticulate)
use_python(python = "C:/Users/Junrui/Anaconda3/python.exe")
repl_python()
import pandas as pd
import numpy as np
s = pd.Series([1,3,5,6,8])
s
from keras.datasets import reuters
(train_data, train_labels), (test_data, test_labels) = reuters.load_data(num_words=10000)
train_data
def vectorize_sequences(sequences, dimension=10000):
results = np.zeros((len(sequences), dimension))
for i, sequence in enumerate(sequences):
results[i, sequence] = 1.
return results
x_train = vectorize_sequences(train_data)
x_test = vectorize_sequences(test_data)
x_train
from keras.utils.np_utils import to_categorical
one_hot_train_labels = to_categorical(train_labels)
one_hot_test_labels = to_categorical(test_labels)
one_hot_train_labels
from keras import models
from keras import layers
model = models.Sequential()
model.add(layers.Dense(64, activation='relu', input_shape=(10000,)))
model.add(layers.Dense(64, activation='relu'))
model.add(layers.Dense(46, activation='softmax'))
model.compile(optimizer='rmsprop',loss='categorical_crossentropy',metrics=['accuracy'])
x_val = x_train[:1000]
partial_x_train = x_train[1000:]
y_val = one_hot_train_labels[:1000]
partial_y_train = one_hot_train_labels[1000:]
history = model.fit(partial_x_train,
partial_y_train,
epochs=20,
batch_size=512,
validation_data=(x_val, y_val))
import matplotlib.pyplot as plt
loss = history.history['loss']
val_loss = history.history['val_loss']
epochs = range(1, len(loss) + 1)
plt.plot(epochs, loss, 'bo', label='Training loss')
plt.plot(epochs, val_loss, 'b', label='Validation loss')
plt.title('Training and validation loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.show()
install.packages("tidyverse")
install.packages("jsonlite", type = "source")
install.packages("devtools")
install.packages(c("cpp11", "gert", "gh", "remotes", "reprex", "tinytex", "vctrs"))
install.packages(c("broom", "cli", "dbplyr", "devtools", "DT", "haven", "highr", "knitr", "pillar", "pkgload", "processx", "tibble", "tidyverse", "viridis", "viridisLite", "withr"))
install.packages("callr")
sqrt(-1)
library(readr)
Data = read_csv("C:/Users/Junrui/Downloads/Pdat.csv")
View(Data)
str(Data)
View(Data)
str(Data)
model <- lm(amp ~ bs(age)+ sex, data =Data)
library(splines)
model <- lm(amp ~ bs(age)+ sex, data =Data)
summary (model)
agelims<-range(Data$age)
age.grid<-seq(from=agelims[1], to=agelims[2])
age.grid
pred<-predict(model, newdata = list(age=age.grid, sex = rep(0,length(agelims))),se=T)
pred<-predict(model, newdata = data.frame(age=age.grid, sex = rep(0,length(agelims))),se=T)
pred<-predict(model, newdata = data.frame(age=age.grid, sex = rep(0,length(age.grid))),se=T)
pred
plot(Data$age,Data$amp, main='Regression Spline plot')
lines(age.grid, pred$fit,col='red', lwd=4)
plot(pred)
plot(x = age.grid, y = pred$fit)
plot(x = age.grid, y = pred$fit, type = "l")
source("~/.active-rstudio-document", echo=TRUE)
library(readr)
Data = read_csv("C:/Users/Junrui/Downloads/Pdat.csv")
model <- lm(amp ~ bs(age)+ sex, data =Data)
summary (model)
agelims<-range(Data$age)
age.grid<-seq(from=agelims[1], to=agelims[2])
pred_0<-predict(model, newdata = data.frame(age=age.grid, sex = rep(0,length(age.grid))),se=T)
pred_1<-predict(model, newdata = data.frame(age=age.grid, sex = rep(1,length(age.grid))),se=T)
plot(x = age.grid, y = pred$fit, type = "l")
plot(x = age.grid, y = pred$fit, type = "l", xlab = "Age", ylab = "Amplitude", Main = "Amplitude")
plot(x = age.grid, y = pred$fit, type = "l", xlab = "Age", ylab = "Amplitude", main = "Amplitude")
warnings()
plot(x = age.grid, y = pred$fit, type = "l", xlab = "Age", ylab = "Amplitude", main = "Amplitude")
rm(list = ls())
library(readr)
Data = read_csv("C:/Users/Junrui/Downloads/Pdat.csv")
model <- lm(amp ~ bs(age)+ sex, data =Data)
age.grid<-seq(from=min(Data$age), to=max(Data$age))
pred_0<-predict(model, newdata = data.frame(age=age.grid, sex = rep(0,length(age.grid))),se=T)
pred_1<-predict(model, newdata = data.frame(age=age.grid, sex = rep(1,length(age.grid))),se=T)
plot(x = age.grid, y = pred_0$fit, type = "l", xlab = "Age", ylab = "Amplitude", main = "Amplitude", col = "blue",lwd = 2)
lines(x = age.grid, y = pred_1$fit, type = "l", lwd = 2)
lines(x = age.grid, y = pred_1$fit, type = "l", lwd = 2, col = "red")
summary(model)
View(Data)
rm(list = ls())
library(readr)
Data = read_csv("C:/Users/Junrui/Downloads/Pdat.csv")
model <- lm(acrophase ~ bs(age)+ sex, data =Data)
age.grid<-seq(from=min(Data$age), to=max(Data$age))
pred_0<-predict(model, newdata = data.frame(age=age.grid, sex = rep(0,length(age.grid))),se=T)
pred_1<-predict(model, newdata = data.frame(age=age.grid, sex = rep(1,length(age.grid))),se=T)
plot(x = age.grid, y = pred_0$fit, type = "l", xlab = "Age", ylab = "Amplitude", main = "Amplitude", col = "blue",lwd = 2)
lines(x = age.grid, y = pred_1$fit, type = "l", lwd = 2, col = "red")
legend("topright",legend = "")
plot(x = age.grid, y = pred_0$fit, type = "l", xlab = "Age", ylab = "Amplitude", main = "Amplitude", col = "blue",lwd = 2, ylim = c(11,17))
lines(x = age.grid, y = pred_1$fit, type = "l", lwd = 2, col = "red")
legend("topright",legend = "")
model <- lm(acrophase ~ bs(age)* sex, data =Data)
age.grid<-seq(from=min(Data$age), to=max(Data$age))
pred_0<-predict(model, newdata = data.frame(age=age.grid, sex = rep(0,length(age.grid))),se=T)
pred_1<-predict(model, newdata = data.frame(age=age.grid, sex = rep(1,length(age.grid))),se=T)
plot(x = age.grid, y = pred_0$fit, type = "l", xlab = "Age", ylab = "Amplitude", main = "Amplitude", col = "blue",lwd = 2, ylim = c(11,17))
lines(x = age.grid, y = pred_1$fit, type = "l", lwd = 2, col = "red")
legend("topright",legend = "")
legend("topright",legend = c("Female","Male"), lty = c(1,1), col = c("blue","red"), lwd = 2, horiz = F,bty = NA)
legend("topright",legend = c("Female","Male"), lty = c(1,1), col = c("blue","red"), lwd = 2, horiz = F,bty = "N")
plot(x = age.grid, y = pred_0$fit, type = "l", xlab = "Age", ylab = "Acrophase", main = "Acrophase", col = "blue",lwd = 2, ylim = c(14,17))
lines(x = age.grid, y = pred_1$fit, type = "l", lwd = 2, col = "red")
legend("topright",legend = c("Female","Male"), lty = c(1,1), col = c("blue","red"), lwd = 2, horiz = F,bty = "N")
summary(model)
View(Data)
model <- lm(acrophase ~ bs(age) * sex + factor(race), data =Data)
age.grid<-seq(from=min(Data$age), to=max(Data$age))
str(dATA)
str(Data)
table(Data$race)
data.frame(age=age.grid, sex = rep(0,length(age.grid)), race = rep(1, length(age.grid)))
rm(list = ls())
library(readr)
Data = read_csv("C:/Users/Junrui/Downloads/Pdat.csv")
model <- lm(acrophase ~ bs(age) * sex + factor(race), data =Data)
age.grid<-seq(from=min(Data$age), to=max(Data$age))
pred_0<-predict(model, newdata = data.frame(age=age.grid, sex = rep(0,length(age.grid)), race = rep(1, length(age.grid))),se=T)
pred_1<-predict(model, newdata = data.frame(age=age.grid, sex = rep(1,length(age.grid)), race = rep(1, length(age.grid))),se=T)
plot(x = age.grid, y = pred_0$fit, type = "l", xlab = "Age", ylab = "Acrophase", main = "Acrophase", col = "blue",lwd = 2, ylim = c(14,17))
lines(x = age.grid, y = pred_1$fit, type = "l", lwd = 2, col = "red")
legend("topright",legend = c("Female","Male"), lty = c(1,1), col = c("blue","red"), lwd = 2, horiz = F,bty = "N")
legend("topright",legend = c("Female","Male"), lty = c(1,1), col = c("blue","red"), lwd = 2, horiz = F,bty = "n")
plot(x = age.grid, y = pred_0$fit, type = "l", xlab = "Age", ylab = "Acrophase", main = "Acrophase", col = "blue",lwd = 2, ylim = c(14,17))
lines(x = age.grid, y = pred_1$fit, type = "l", lwd = 2, col = "red")
legend("topright",legend = c("Female","Male"), lty = c(1,1), col = c("blue","red"), lwd = 2, horiz = F,bty = "n")
View(Data)
plot(x = age.grid, y = pred_0$fit, type = "l", xlab = "Age", ylab = "Acrophase", main = "Acrophase", col = "blue",lwd = 2, ylim = c(14,16.5))
lines(x = age.grid, y = pred_1$fit, type = "l", lwd = 2, col = "red")
legend("topright",legend = c("Female","Male"), lty = c(1,1), col = c("blue","red"), lwd = 2, horiz = F,bty = "n")
4/3
4 %% 3
? %*%
4 %*% 3
c(1,2) * t(c(3,2))
c(1,2) * (c(3,2))
library(tidyverse)
install.packages(c("broom", "bslib", "cachem", "cli", "colorspace", "cpp11", "cubature", "curl", "devtools", "dplyr", "fansi", "furrr", "gargle", "gert", "ggplot2", "googledrive", "hardhat", "hms", "htmlTable", "isoband", "ks", "lme4", "matrixStats", "mime", "modeldata", "multicool", "mvtnorm", "parallelly", "parsnip", "pillar", "plot3D", "Rcpp", "refund", "remotes", "rmarkdown", "rversions", "slider", "stringi", "tableone", "testthat", "tibble", "tinytex", "workflows", "xfun", "zip"))
install.packages(c("blob", "broom", "credentials", "e1071", "googlesheets4", "grpreg", "jpeg", "matrixStats", "parallelly", "parsnip", "pillar", "readr", "rvest", "survey", "tibble", "tune", "utf8", "workflowsets"))
774 - 37 - 67 - 1 - 11
cite("ActFrag")
citation("ActFrag")
install.packages("cranlog")
install.packages("cranlogs")
cranlogs::cran_downloads("ActFrag", from = "2019-01-01", to = "2021-08-27")
a = cranlogs::cran_downloads("ActFrag", from = "2019-01-01", to = "2021-08-27")
sum(a$count)
b = cranlogs::cran_downloads("ActCR", from = "2019-01-01", to = "2021-08-27")
sum(b$count)
View(a)
View(b)
install.packages(c("digest", "knitr", "mime", "tinytex"))
install.packages("stringi")
install.packages(c("glue", "rlang", "tinytex", "xfun"))
47+41+31+24+14+7+5
install.packages(c("digest", "evaluate", "glue", "jsonlite", "knitr", "magrittr", "rlang", "stringi", "tinytex", "xfun", "yaml"))
install.packages(c("knitr", "magrittr", "rlang", "rmarkdown", "tinytex", "xfun"))
library(cosinor)
install.packages("cosinor")
install.packages("tidyverse")
library(dplyr)
install.packages("dplyr")
install.packages("ggplot2")
install.packages(c("tidyverse","devtools"))
install.packages(c("broom", "bslib", "callr", "DBI", "dbplyr", "devtools", "farver", "fontawesome", "generics", "htmlTable", "htmltools", "latticeExtra", "pillar", "pkgload", "processx", "ps", "Rcpp", "rlang", "roxygen2", "sass", "shiny", "stringi", "tibble", "tidyverse", "tinytex"))
install.packages(c("callr", "dtplyr", "evaluate", "forcats", "gert", "googlesheets4", "haven", "Hmisc", "hms", "httr", "knitr", "modelr", "pillar", "readxl", "reprex", "rmarkdown", "rstudioapi", "rvest", "scales", "stringr", "tinytex", "viridisLite", "xfun"))
fish
install.packages(c("brew", "broom", "cli", "crayon", "curl", "desc", "dplyr", "evaluate", "gargle", "gert", "gh", "gitcreds", "gtable", "httpuv", "isoband", "jsonlite", "lifecycle", "openssl", "purrr", "ragg", "readr", "rlang", "rmarkdown", "rversions", "testthat", "tidyr", "tinytex", "vctrs", "vroom", "xfun", "zip", "zoo"))
install.packages(c("commonmark", "cpp11", "data.table", "devtools", "digest", "fontawesome", "jsonlite", "markdown", "openssl", "processx", "ps", "ragg", "shiny", "sys", "tidyselect", "vctrs", "xfun", "yaml", "zip"))
search()
df <- data.frame(
x = c(4, 5, 6),
y = c('one', 'two', 'three')
)
df
gc()
devtools:::test_coverage_active_file()
pkgdown:::build_site_external()
install.packages(c("bit", "broom", "bslib", "callr", "cli", "data.table", "digest", "evaluate", "gert", "ggplot2", "highr", "Hmisc", "htmltools", "htmlwidgets", "httpuv", "isoband", "jpeg", "jsonlite", "knitr", "lubridate", "markdown", "matrixStats", "modelr", "openssl", "pkgbuild", "pkgdown", "pkgload", "png", "purrr", "RcppEigen", "rmarkdown", "roxygen2", "sass", "shiny", "stringr", "testthat", "tinytex", "vctrs", "whisker", "xfun"))
install.packages(c("bit", "broom", "bslib", "callr", "cli", "data.table", "digest", "evaluate", "gert", "ggplot2", "highr", "Hmisc", "htmltools", "htmlwidgets", "httpuv", "isoband", "jpeg", "jsonlite", "knitr", "lubridate", "markdown", "matrixStats", "modelr", "openssl", "pkgbuild", "pkgdown", "pkgload", "png", "purrr", "RcppEigen", "rmarkdown", "roxygen2", "sass", "shiny", "stringr", "testthat", "tinytex", "vctrs", "whisker", "xfun"))
install.packages(c("bit", "broom", "bslib", "callr", "cli", "data.table", "digest", "evaluate", "gert", "ggplot2", "highr", "Hmisc", "htmltools", "htmlwidgets", "httpuv", "isoband", "jpeg", "jsonlite", "knitr", "lubridate", "markdown", "matrixStats", "modelr", "openssl", "pkgbuild", "pkgdown", "pkgload", "png", "purrr", "RcppEigen", "rmarkdown", "roxygen2", "sass", "shiny", "stringr", "testthat", "tinytex", "vctrs", "whisker", "xfun"))
install.packages(c("bit", "broom", "bslib", "callr", "cli", "data.table", "digest", "evaluate", "gert", "ggplot2", "highr", "Hmisc", "htmltools", "htmlwidgets", "httpuv", "isoband", "jpeg", "jsonlite", "knitr", "lubridate", "markdown", "matrixStats", "modelr", "openssl", "pkgbuild", "pkgdown", "pkgload", "png", "purrr", "RcppEigen", "rmarkdown", "roxygen2", "sass", "shiny", "stringr", "testthat", "tinytex", "vctrs", "whisker", "xfun"))
install.packages(c("bit", "broom", "bslib", "callr", "cli", "data.table", "digest", "evaluate", "gert", "ggplot2", "highr", "Hmisc", "htmltools", "htmlwidgets", "httpuv", "isoband", "jpeg", "jsonlite", "knitr", "lubridate", "markdown", "matrixStats", "modelr", "openssl", "pkgbuild", "pkgdown", "pkgload", "png", "purrr", "RcppEigen", "rmarkdown", "roxygen2", "sass", "shiny", "stringr", "testthat", "tinytex", "vctrs", "whisker", "xfun"))
install.packages("tidymodels")
parsnip:::parsnip_addin()
install.packages(c("broom", "cli", "colorspace", "curl", "dbplyr", "DT", "evaluate", "fansi", "fs", "htmlwidgets", "httpuv", "knitr", "lava", "lubridate", "modeldata", "parallelly", "progressr", "purrr", "ragg", "Rcpp", "recipes", "rmarkdown", "sass", "stringi", "tidyr", "timechange", "timeDate", "vctrs", "vroom", "yaml"))
install.packages("qdap")
library(qdap)
install.packages(c("askpass", "curl", "dplyr", "fansi", "ggplot2", "gtable", "labeling", "openssl", "plotrix", "plyr", "qdapRegex", "RCurl", "utf8", "vctrs", "withr", "XML"))
getwd()
setwd("D:/Dropbox/web/junruidi.github.io/")
rmarkdown::render_site()
