allDataHour50_female$NormWts= normalize(allDataHour50_female$wtmec4yr_adj)*nrow(allDataHour50_female)
## - Save dataset
#save(allDataHour50, file = "allDataHour50.RData")
# read data
#load("C:/Users/DEBANGAN/Dropbox/NHANES ISI/allDataHour50.RData")
#load("C:/Users/Vadim/Dropbox/Papers/NHANES explore/allDataHour50.RData")
## - create design matrix
dataSvy <- svydesign(id= ~SDMVPSU, strata = ~SDMVSTRA, weights = ~NormWts,
data = allDataHour50, nest = TRUE)
library(limma)
library(devtools)
#install_github("swihart/lasagnar")
library(fields)
library(lasagnar)
library(ggplot2)
library(reshape2)
library(RColorBrewer)
library(colorspace)
library(refund)
library(MASS)
library(cluster)
library(survey)
library(survival)
library(moments)
library(entropy)
library(nhanesaccel)
library(SDMTools)
require(gamlss)
removeBadDays <- function(dataPath, cohort = 2003, threshold = 600){
## Note there are 3 potential 'flags' that data quality is an issue:
##      2 are generated by NHANES (PAXSTAT, PAXCAL) -> 1 means no issue, 2 means there is an issue
##      we take the approach that a flag on either variable means that day should not be included
##      in the analysis.
##      The third flag is based on our wear/nonwear flags so the initial step is to remove days
##      where we have an issue in the data
cohort_years <- seq(2003, 2013, by=2)
pathExt      <- paste('_', LETTERS[3:26], '.csv', sep='')[which(cohort_years == cohort)]
## load data
activity     <- read.csv(paste(dataPath, 'PAXINTEN', pathExt, sep=''), head = TRUE)
flags        <- read.csv(paste(dataPath, 'Flags', pathExt, sep=''), head = TRUE)
## get nonwear flag
flag_nonwear <- rowSums(flags[, paste('MIN', 1:1440, sep='')], na.rm = TRUE) < threshold
## re-code all non-wear time to be 0 counts
activity[, paste('MIN', 1:1440, sep='')] <- activity[, paste('MIN', 1:1440, sep='')]*flags[, paste('MIN', 1:1440, sep='')]
## remove nonwear days and days flagged by NHANES
activity     <- activity[!(flag_nonwear | activity$PAXSTAT == 2 | activity$PAXCAL == 2 | activity$PAXCAL == 9),]
# activity     <- activity[!(flag_nonwear),]
activity
}
library('foreign')
library('survey')
library('survival')
library('plyr')
library('nhanesaccel')
library(limma)
library(devtools)
#install_github("swihart/lasagnar")
library(fields)
library(lasagnar)
library(ggplot2)
library(reshape2)
library(RColorBrewer)
library(colorspace)
library(refund)
library(MASS)
library(cluster)
library(survey)
library(survival)
library(moments)
library(entropy)
library(nhanesaccel)
library(SDMTools)
dataPathProcessed = "~/Dropbox/NHANES ISI/Processed/"
## in this case we want both 2003-2004 and 2005-2006 cohorts
cohort1    <- 2003
cohort2    <- 2005
"~/Dropbox/NHANES ISI/Processed/"
## --get activity--
## Here we combine the loading of the processed activity data with a function that automatically removed days
## which qualify as `bad'. Here, bad means that there are less than 10 hours of wear-time in a given day OR
## either of the two NHANES provided quality flags indicate data quality concerns
threshold  <- 10*60
Act_1       <- removeBadDays(dataPath = dataPathProcessed, cohort = cohort1, threshold = threshold)
Act_2       <- removeBadDays(dataPath = dataPathProcessed, cohort = cohort2, threshold = threshold)
ValidDays=1
## Remove subjects with less than'ValidDays' days of valid data
## VVZ: comment out if we want to include everyone with at least one valid day
Act1 <- subset(Act_1, SEQN %in% names(table(Act_1$SEQN)[table(Act_1$SEQN) >= ValidDays]))
Act2 <- subset(Act_2, SEQN %in% names(table(Act_2$SEQN)[table(Act_2$SEQN) >= ValidDays]))
##Keeping Counts of Subjects who are dropped
ActRemove1 <- subset(Act_1, SEQN %in% names(table(Act_1$SEQN)[table(Act_1$SEQN) < ValidDays]))
ActRemove2 <- subset(Act_2, SEQN %in% names(table(Act_2$SEQN)[table(Act_2$SEQN) < ValidDays]))
## --get covariates--
Covar1 <- read.csv(paste(dataPathProcessed, 'Covariate_C.csv', sep=''), head = TRUE)
Covar2 <- read.csv(paste(dataPathProcessed, 'Covariate_D.csv', sep=''), head = TRUE)
varsInterest <- c('SEQN','WTINT2YR','WTMEC2YR','SDMVPSU','SDMVSTRA',
'Age', 'Male','Age','wave')
## Create demographics variables
Covar1$Age <- as.integer(Covar1$RIDAGEEX/12)
Covar1$Male <- as.numeric(Covar1$RIAGENDR == 1)
Covar1$BMI <- Covar1$BMXBMI
table(Covar1$RIDRETH1)
Covar1$White         <- ifelse(Covar1$RIDRETH1 == 3, 1, 0)
Covar1$Black         <- ifelse(Covar1$RIDRETH1 == 4, 1, 0)
Covar1$OtherRace     <- ifelse(Covar1$RIDRETH1 %in% c(1,2,5), 1, 0)
## Create indicator variables for education
Covar1$LessThanHS  <- ifelse(Covar1$DMDEDUC2 %in% c(1:2), 1, 0)
Covar1$HighSchool  <- ifelse(Covar1$DMDEDUC2 %in% c(3), 1, 0)
Covar1$MoreThanHS  <- ifelse(Covar1$DMDEDUC2 %in% c(4:5), 1, 0)
Covar1$MissingEduc <- ifelse(is.na(Covar1$DMDEDUC2) | Covar1$DMDEDUC2 %in% c(7,9), 1, 0)
## Create indicator variables for certain comorbidities
Covar1$Diabetes <- ifelse(Covar1$DIQ010 == 1, 1, 0)
Covar1$CHF      <- ifelse(Covar1$MCQ160B == 1, 1, 0)
Covar1$CHD      <- ifelse(Covar1$MCQ160C == 1, 1, 0)
Covar1$Cancer   <- ifelse(Covar1$MCQ220 == 1, 1, 0)
Covar1$Stroke   <- ifelse(Covar1$MCQ160F == 1, 1, 0)
## Create indicator variables for smoking
Covar1$CurrentSmoker <- ifelse(Covar1$SmokeCigs == 'Current' & !is.na(Covar1$SmokeCigs), 1, 0)
Covar1$FormerSmoker  <- ifelse(Covar1$SmokeCigs == 'Former' & !is.na(Covar1$SmokeCigs), 1, 0)
Covar1$NeverSmoker  <- ifelse(Covar1$SmokeCigs == 'Never' & !is.na(Covar1$SmokeCigs), 1, 0)
Covar1$MissingSmoke  <- ifelse(is.na(Covar1$SmokeCigs), 1, 0)
## Create indicator variables for drinking
Covar1$NeverDrinker     <- ifelse(Covar1$Alcohol == 'Never' & !is.na(Covar1$Alcohol), 1, 0)
Covar1$FormerDrinker    <- ifelse(Covar1$Alcohol == 'Former' & !is.na(Covar1$Alcohol), 1, 0)
Covar1$CurrentDrinker   <- ifelse(Covar1$Alcohol == 'Current'& !is.na(Covar1$Alcohol), 1, 0)
Covar1$HeavyDrinker     <- ifelse(Covar1$DrinkStatus == 'Heavy Drinker'& !is.na(Covar1$DrinkStatus), 1, 0)
Covar1$ModerateDrinker  <- ifelse(Covar1$DrinkStatus == 'Moderate Drinker' & !is.na(Covar1$DrinkStatus), 1, 0)
Covar1$MissingAlcohol   <- ifelse(is.na(Covar1$DrinkStatus), 1, 0)
## Create indicator variables for mobility
Covar1$MobilityProblem  <- ifelse(Covar1$MobilityProblem == 'Any Difficulty', 1, 0)
## Create wave variable for survey weight adjustment step
Covar1$wave <- 1
Covar2$Age <- as.integer(Covar2$RIDAGEEX/12)
Covar2$Male <- as.numeric(Covar2$RIAGENDR == 1)
Covar2$BMI <- Covar2$BMXBMI
## Create indicator variables for race
Covar2$White         <- ifelse(Covar2$RIDRETH1 == 3, 1, 0)
Covar2$Black         <- ifelse(Covar2$RIDRETH1 == 4, 1, 0)
Covar2$OtherRace     <- ifelse(Covar2$RIDRETH1 %in% c(1,2,5), 1, 0)
Covar2$LessThanHS  <- ifelse(Covar2$DMDEDUC2 %in% c(1:2), 1, 0)
Covar2$HighSchool  <- ifelse(Covar2$DMDEDUC2 %in% c(3), 1, 0)
Covar2$MoreThanHS  <- ifelse(Covar2$DMDEDUC2 %in% c(4:5), 1, 0)
Covar2$MissingEduc <- ifelse(is.na(Covar2$DMDEDUC2) | Covar2$DMDEDUC2 %in% c(7,9), 1, 0)
## Create indicator variables for certain comorbidities
Covar2$Diabetes <- ifelse(Covar2$DIQ010 == 1, 1, 0)
Covar2$CHF      <- ifelse(Covar2$MCQ160B == 1, 1, 0)
Covar2$CHD      <- ifelse(Covar2$MCQ160C == 1, 1, 0)
Covar2$Cancer   <- ifelse(Covar2$MCQ220 == 1, 1, 0)
Covar2$Stroke   <- ifelse(Covar2$MCQ160F == 1, 1, 0)
## Create indicator variables for smoking
Covar2$CurrentSmoker <- ifelse(Covar2$SmokeCigs == 'Current' & !is.na(Covar2$SmokeCigs), 1, 0)
Covar2$FormerSmoker  <- ifelse(Covar2$SmokeCigs == 'Former' & !is.na(Covar2$SmokeCigs), 1, 0)
Covar2$NeverSmoker  <- ifelse(Covar2$SmokeCigs == 'Never' & !is.na(Covar2$SmokeCigs), 1, 0)
Covar2$MissingSmoke  <- ifelse(is.na(Covar2$SmokeCigs), 1, 0)
## Create indicator variables for drinking
Covar2$NeverDrinker     <- ifelse(Covar2$Alcohol == 'Never' & !is.na(Covar2$Alcohol), 1, 0)
Covar2$FormerDrinker    <- ifelse(Covar2$Alcohol == 'Former' & !is.na(Covar2$Alcohol), 1, 0)
Covar2$CurrentDrinker   <- ifelse(Covar2$Alcohol == 'Current'& !is.na(Covar2$Alcohol), 1, 0)
Covar2$HeavyDrinker     <- ifelse(Covar2$DrinkStatus == 'Heavy Drinker'& !is.na(Covar2$DrinkStatus), 1, 0)
Covar2$ModerateDrinker  <- ifelse(Covar2$DrinkStatus == 'Moderate Drinker' & !is.na(Covar2$DrinkStatus), 1, 0)
Covar2$MissingAlcohol   <- ifelse(is.na(Covar2$DrinkStatus), 1, 0)
Covar2$MobilityProblem  <- ifelse(Covar2$MobilityProblem == 'Any Difficulty', 1, 0)
## Create wave variable for survey weight adjustment step
Covar2$wave <- 2
# 'wave')
varsInterest <- c('SEQN','WTINT2YR','WTMEC2YR','SDMVPSU','SDMVSTRA','White','Black','OtherRace',
'Age', 'Male','Age','wave')
Covar1 <- Covar1[,varsInterest]
Covar2 <- Covar2[,varsInterest]
Covar1=Covar1[complete.cases(Covar1),]
Covar2=Covar2[complete.cases(Covar2),]
colnames(Covar1)[colnames(Covar1) %in% c('WTINT2YR','WTMEC2YR')] <- tolower(colnames(Covar1)[colnames(Covar1) %in% c('WTINT2YR','WTMEC2YR')])
colnames(Covar2)[colnames(Covar2) %in% c('WTINT2YR','WTMEC2YR')] <- tolower(colnames(Covar2)[colnames(Covar2) %in% c('WTINT2YR','WTMEC2YR')])
valid <- 1
allData1   <- cbind.data.frame(Covar1[match(Act1$SEQN, Covar1$SEQN),],
valid,
Act1[, -1])
allData2   <- cbind.data.frame(Covar2[match(Act2$SEQN, Covar2$SEQN),],
valid,
Act2[, -1])
TableRemove1 <- as.data.frame(table(Covar1[Covar1$SEQN %in% ActRemove1$SEQN,]$Age))
TableRemove2 <- as.data.frame(table(Covar2[Covar2$SEQN %in% ActRemove2$SEQN,]$Age))
colnames(TableRemove1) <- colnames(TableRemove2) <- c("Age","Freq")
TableRemove <- merge(TableRemove1,TableRemove2,by="Age",all=TRUE)
TableRemove1 <- as.data.frame(table(Covar1[Covar1$SEQN %in% ActRemove1$SEQN,]$Age))
TableRemove2 <- as.data.frame(table(Covar2[Covar2$SEQN %in% ActRemove2$SEQN,]$Age))
colnames(TableRemove1)
## -- create merged dataset that includes 2003-2004 and 2005-2006 cohorts --
allData = rbind(allData1, allData2)
infoCols <- substr(colnames(allData), 1, 3) != 'MIN'
x.unlist = allData[,!infoCols]
View(x.unlist)
for(i in 1:24){
allData[[paste0('act', ifelse(i < 10, paste0('0',i), i))]] <- rowSums(log(x.unlist[,((60*(i-1)+1):(60*i))]+1), na.rm = TRUE)
}
dim(allData)
names(allData)
infoMinCols <- substr(colnames(allData), 1, 3) != 'MIN'
avgDaily  <- by(allData[,infoMinCols], allData$SEQN, function(x){
## Identify which columns are not associated with activity counts
## and, by extension, which columns are associaetd with activity counts
infoActCols <- substr(colnames(x), 1, 3) != 'act'
## Take the log of the sum of activity counts across all days, divided by
## the total number of days.
act   <- colSums(x[,!infoActCols], na.rm = TRUE)/nrow(x)
## return the info columns (covariate) as well as the logSum summary measure
x[1, !infoActCols] = act
cbind.data.frame(x[1, infoActCols], x[1, !infoActCols])
})
allDataHour      <- ldply(avgDaily)[, -1]
allDataHour50 <- allDataHour
attach(allDataHour50)
### - Drop incomplete cases
# X = cbind.data.frame(permth_exm, mortstat,
#                      Age, Male, BMI,
#                      Mexican, Black, HispanicOther, OtherRace,
#                      HighSchool, MoreThanHS,
#                      Diabetes, CHF, CHD, Cancer, Stroke,
#                      CurrentSmoker, FormerSmoker,
#                      FormerDrinker, ModerateDrinker,
#                      HeavyDrinker, MissingAlcohol,
#                      MobilityProblem)
X = cbind.data.frame(Age, Male, White, Black, OtherRace)
complete.cases.id = complete.cases(X)
allDataHour50 = allDataHour50[complete.cases.id,]
allDataHour50.wave1 = subset(allDataHour50, wave == 1)
allDataHour50.wave2 = subset(allDataHour50, wave == 2)
allDataHour50.wave1$valid    <- 1
allDataHour50.wave1.adjusted <- nhanes.accel.reweight(acceldata = allDataHour50.wave1,  wave = 1, seqn.column = 1,
include.column = which(colnames(allDataHour50.wave1) == 'valid'))
allDataHour50.wave2$valid    <- 1
allDataHour50.wave2.adjusted <- nhanes.accel.reweight(acceldata = allDataHour50.wave2,  wave = 2, seqn.column = 1,
include.column = which(colnames(allDataHour50.wave2) == 'valid'))
allDataHour50 = rbind(allDataHour50.wave1.adjusted, allDataHour50.wave2.adjusted)
allDataHour50$wtmec4yr_adj = allDataHour50$wtmec2yr_adj/2
allDataHour50_white = subset(allDataHour50, White == 1)
allDataHour50_white.wave1 =  subset(allDataHour50_white wave == 1)
allDataHour50_white.wave1 =  subset(allDataHour50_white, wave == 1)
allDataHour50_white.wave2 =  subset(allDataHour50_white, wave == 2)
allDataHour50_white.wave2.adjusted <- nhanes.accel.reweight(acceldata = allDataHour50_white.wave2,  wave = 2, seqn.column = 1,
include.column = which(colnames(allDataHour50_white.wave2) == 'valid'))
allDataHour50_white.wave1.adjusted <- nhanes.accel.reweight(acceldata = allDataHour50_white.wave1,  wave = 1, seqn.column = 1,
include.column = which(colnames(allDataHour50_white.wave1) == 'valid'))
allDataHour50_white = rbind(allDataHour50_white.wave1.adjusted, allDataHour50_white.wave2.adjusted)
allDataHour50_white$wtmec4yr_adj = allDataHour50_white$wtmec2yr_adj/2
allDataHour50_other = subset(allDataHour50, OtherRace == 1)
allDataHour50_other.wave1 =  subset(allDataHour50_other, wave == 1)
allDataHour50_other.wave2 =  subset(allDataHour50_other, wave == 2)
allDataHour50_other.wave1.adjusted <- nhanes.accel.reweight(acceldata = allDataHour50_other.wave1,  wave = 1, seqn.column = 1,
include.column = which(colnames(allDataHour50_other.wave1) == 'valid'))
allDataHour50_other.wave2.adjusted <- nhanes.accel.reweight(acceldata = allDataHour50_other.wave2,  wave = 2, seqn.column = 1,
include.column = which(colnames(allDataHour50_other.wave2) == 'valid'))
allDataHour50_other = rbind(allDataHour50_other.wave1.adjusted, allDataHour50_other.wave2.adjusted)
allDataHour50_other$wtmec4yr_adj = allDataHour50_other$wtmec2yr_adj/2
allDataHour50 = rbind(allDataHour50_white,allDataHour50_other)
View(allDataHour50)
## - create Daily TAC, two-hour TAC (thTAC), percentage of thTAC (pthTAC), four-hour TAC (fhTAC), and pfhTAC
infoActCols <- substr(colnames(allDataHour50), 1, 3) == 'act'
hTAC = allDataHour50[, infoActCols]
allDataHour50$TLAC = rowSums(hTAC, na.rm = TRUE)
#
# ## - create the ratio of the morning and evening
# allDataHour50$pfhTAC03plus06 = allDataHour50$pfhTAC03 + allDataHour50$pfhTAC06
# allDataHour50$ratio_pfhTAC03plus06 = allDataHour50$pfhTAC03/allDataHour50$pfhTAC03plus06
#
# allDataHour50$pthTAC06plus12 = allDataHour50$pthTAC06 + allDataHour50$pthTAC12
# allDataHour50$ratio_pthTAC06plus12 = allDataHour50$pthTAC06/allDataHour50$pthTAC06plus12
# allDataHour50$LTAC=log(allDataHour50$dTAC)
# allDataHour50$MTAC=(allDataHour50$dTAC)/1440
#
normalize=function(v){return(v/sum(v))}
allDataHour50$NormWts= normalize(allDataHour50$wtmec4yr_adj)*nrow(allDataHour50)
normalize
allDataHour50_white = subset(allDataHour50, White == 1)
allDataHour50_white$NormWts= normalize(allDataHour50_white$wtmec4yr_adj)*nrow(allDataHour50_white)
allDataHour50_other = subset(allDataHour50, OtherRace== 1)
allDataHour50_other = subset(allDataHour50, OtherRace== 1)
allDataHour50_other$NormWts= normalize(allDataHour50_other$wtmec4yr_adj)*nrow(allDataHour50_other)
m4_male = lms(TLAC,Age,data=allDataHour50_male,cent=c(5,10,25,50,75,90,95,97),weights=allDataHour50_male$NormWts)
m4_male = lms(TLAC,Age,data=allDataHour50_other,cent=c(5,10,25,50,75,90,95,97),weights=allDataHour50_male$NormWts)
setwd("~/Dropbox/Junrui Di/Other papers/NHANES African/")
load("data/features.rda")
View(allDataHour50_white.wave2)
names(allDataHour50_other)
View(allDataHour50_other)
View(dat40)
rm(list = ls())
setwd("~/Dropbox/Junrui Di/Other papers/NHANES African/")
load("data/features.rda")
dat40$include = 1
AA = subset(dat40, race == "AA")
CW = subset(dat40, race == "CW")
OT = subset(dat40, race == "others")
m4_male = lms(TLAC,Age,data=allDataHour50_other,cent=c(5,10,25,50,75,90,95,97),weights=allDataHour50_male$NormWts)
rm(list = ls())
setwd("~/Dropbox/Junrui Di/Other papers/NHANES African/")
load("data/features.rda")
dat40$include = 1
AA = subset(dat40, race == "AA")
CW = subset(dat40, race == "CW")
OT = subset(dat40, race == "others")
#reweright data
library(nhanesaccel)
normalize=function(v){return(v/sum(v))}
c1 = subset(AA,yr==34)
d1 = subset(AA,yr==56)
c2 = nhanes.accel.reweight(acceldata = c1, wave = 1, seqn.column = 1,
include.column = 12)
d2 = nhanes.accel.reweight(acceldata = d1, wave = 2, seqn.column = 1,
include.column = 12)
AA = rbind(c2, d2)
AA$wtmec4yr_adj = AA$wtmec2yr_adj/2
sum(AA$wtmec2yr_adj)
sum(AA$wtmec4yr_adj'')
sum(AA$wtmec4yr_adj)
#AA$wt4yr = c(c2$wtmec2yr_adj/2,d2$wtmec2yr_adj/2)
#AA$wt4yr_norm= normalize(AA$wt4yr)*nrow(AA)
AA$wt4yr_norm= normalize(AA$wtmec4yr_adj)*nrow(AA)
sum(AA$wtmec4yr_adj)
sum(AA$wt4yr_norm)
rm(list = ls())
setwd("~/Dropbox/Junrui Di/Other papers/NHANES African/")
load("data/features.rda")
dat40$include = 1
AA = subset(dat40, race == "AA")
CW = subset(dat40, race == "CW")
OT = subset(dat40, race == "others")
normalize=function(v){return(v/sum(v))}
c1 = subset(CW,yr==34)
d1 = subset(CW,yr==56)
c2 = nhanes.accel.reweight(acceldata = c1, wave = 1, seqn.column = 1,
include.column = 12)
d2 = nhanes.accel.reweight(acceldata = d1, wave = 2, seqn.column = 1,
include.column = 12)
# CW$wt4yr = c(c2$wtmec2yr_adj/2,d2$wtmec2yr_adj/2)
# CW$wt4yr_norm= normalize(CW$wt4yr)*nrow(CW)
CW = rbind(c2, d2)
CW$wtmec4yr_adj = CW$wtmec2yr_adj/2
CW$wt4yr_norm= normalize(CW$wtmec4yr_adj)*nrow(CW)
sum(CW$wt4yr_norm)
rm(list = ls())
setwd("~/Dropbox/Junrui Di/Other papers/NHANES African/")
load("data/features.rda")
dat40$include = 1
AA = subset(dat40, race == "AA")
CW = subset(dat40, race == "CW")
OT = subset(dat40, race == "others")
c1 = subset(OT,yr==34)
d1 = subset(OT,yr==56)
c2 = nhanes.accel.reweight(acceldata = c1, wave = 1, seqn.column = 1,
include.column = 12)
d2 = nhanes.accel.reweight(acceldata = d1, wave = 2, seqn.column = 1,
include.column = 12)
# OT$wt4yr = c(c2$wtmec2yr_adj/2,d2$wtmec2yr_adj/2)
# OT$wt4yr_norm= normalize(OT$wt4yr)*nrow(OT)
OT = rbind(c2, d2)
OT$wtmec4yr_adj = OT$wtmec2yr_adj/2
OT$wt4yr_norm= normalize(OT$wtmec4yr_adj)*nrow(OT)
normalize=function(v){return(v/sum(v))}
c1 = subset(OT,yr==34)
d1 = subset(OT,yr==56)
c2 = nhanes.accel.reweight(acceldata = c1, wave = 1, seqn.column = 1,
include.column = 12)
d2 = nhanes.accel.reweight(acceldata = d1, wave = 2, seqn.column = 1,
include.column = 12)
# OT$wt4yr = c(c2$wtmec2yr_adj/2,d2$wtmec2yr_adj/2)
# OT$wt4yr_norm= normalize(OT$wt4yr)*nrow(OT)
OT = rbind(c2, d2)
OT$wtmec4yr_adj = OT$wtmec2yr_adj/2
OT$wt4yr_norm= normalize(OT$wtmec4yr_adj)*nrow(OT)
rm(list = ls())
setwd("~/Dropbox/Junrui Di/Other papers/NHANES African/")
load("data/features.rda")
dat40$include = 1
AA = subset(dat40, race == "AA")
CW = subset(dat40, race == "CW")
OT = subset(dat40, race == "others")
#reweright data
library(nhanesaccel)
normalize=function(v){return(v/sum(v))}
c1 = subset(AA,yr==34)
d1 = subset(AA,yr==56)
c2 = nhanes.accel.reweight(acceldata = c1, wave = 1, seqn.column = 1,
include.column = 12)
d2 = nhanes.accel.reweight(acceldata = d1, wave = 2, seqn.column = 1,
include.column = 12)
AA = rbind(c2, d2)
AA$wtmec4yr_adj = AA$wtmec2yr_adj/2
#AA$wt4yr = c(c2$wtmec2yr_adj/2,d2$wtmec2yr_adj/2)
#AA$wt4yr_norm= normalize(AA$wt4yr)*nrow(AA)
AA$wt4yr_norm= normalize(AA$wtmec4yr_adj)*nrow(AA)
c1 = subset(CW,yr==34)
d1 = subset(CW,yr==56)
c2 = nhanes.accel.reweight(acceldata = c1, wave = 1, seqn.column = 1,
include.column = 12)
d2 = nhanes.accel.reweight(acceldata = d1, wave = 2, seqn.column = 1,
include.column = 12)
# CW$wt4yr = c(c2$wtmec2yr_adj/2,d2$wtmec2yr_adj/2)
# CW$wt4yr_norm= normalize(CW$wt4yr)*nrow(CW)
CW = rbind(c2, d2)
CW$wtmec4yr_adj = CW$wtmec2yr_adj/2
CW$wt4yr_norm= normalize(CW$wtmec4yr_adj)*nrow(CW)
c1 = subset(OT,yr==34)
d1 = subset(OT,yr==56)
c2 = nhanes.accel.reweight(acceldata = c1, wave = 1, seqn.column = 1,
include.column = 12)
d2 = nhanes.accel.reweight(acceldata = d1, wave = 2, seqn.column = 1,
include.column = 12)
# OT$wt4yr = c(c2$wtmec2yr_adj/2,d2$wtmec2yr_adj/2)
# OT$wt4yr_norm= normalize(OT$wt4yr)*nrow(OT)
OT = rbind(c2, d2)
OT$wtmec4yr_adj = OT$wtmec2yr_adj/2
OT$wt4yr_norm= normalize(OT$wtmec4yr_adj)*nrow(OT)
save(AA,CW,OT,file = "data/features_reweight.rda")
rm(list = ls())
setwd("~/Dropbox/Junrui Di/Other papers/NHANES African/")
load("data/features_reweight.rda")
View(OT)
rm(list = ls())
setwd("~/Dropbox/Junrui Di/Other papers/NHANES African/")
load("data/features_reweight.rda")
tlac_OT <- lms(Sed,age,data=OT,cent=c(5,10,25,50,75,90,95,97),weights=OT$wt4yr_norm)
names(IOT)
names(OT)
tlac_OT <- lms(TLAC,age,data=OT,cent=c(25,50,75),weights=OT$wt4yr_norm)
tlac_CW <- lms(TLAC,age,data=CW,cent=c(25,50,75),weights=CW$wt4yr_norm)
#Set our working directory.
#This helps avoid confusion if our working directory is
#not our site because of other projects we were
#working on at the time.
setwd("~/Dropbox/web/junruidi.github.io/")
#render your sweet site.
rmarkdown::render_site()
# git add -A
# git commit -m "2nd commit"
# git push origin master
19;9+74.7+5.3
19.9+74.7+5.3
rm(list = ls())
load("~/Dropbox/Junrui Di/fragmentation/Review AJE/aggregate2/data/10hour/act.rda")
load("~/Dropbox/Junrui Di/fragmentation/Review AJE/data/mc_c.rda")
load("~/Dropbox/Junrui Di/fragmentation/Review AJE/data/mc_d.rda")
############################################
##    check race difference in NHANES     ##
##                J Di.12/15/2017         ##
############################################
#1 Get data for 40+
rm(list = ls())
load("~/Dropbox/Junrui Di/fragmentation/Review AJE/aggregate2/data/10hour/act.rda")
load("~/Dropbox/Junrui Di/fragmentation/Review AJE/data/mc_c.rda")
load("~/Dropbox/Junrui Di/fragmentation/Review AJE/data/mc_d.rda")
mc_c$yr = "34"
mc_d$yr = "56"
mc = rbind(mc_c,mc_d)
mc$age = mc$RIDAGEMN/12
#Set our working directory.
#This helps avoid confusion if our working directory is
#not our site because of other projects we were
#working on at the time.
setwd("~/Dropbox/web/junruidi.github.io/")
#render your sweet site.
rmarkdown::render_site()
#Set our working directory.
#This helps avoid confusion if our working directory is
#not our site because of other projects we were
#working on at the time.
setwd("~/Dropbox/web/junruidi.github.io/")
#render your sweet site.
rmarkdown::render_site()
# git add -A
# git commit -m "2nd commit"
# git push origin master
#Set our working directory.
#This helps avoid confusion if our working directory is
#not our site because of other projects we were
#working on at the time.
setwd("~/Dropbox/web/junruidi.github.io/")
#render your sweet site.
rmarkdown::render_site()
# git add -A
# git commit -m "2nd commit"
# git push origin master
#Set our working directory.
#This helps avoid confusion if our working directory is
#not our site because of other projects we were
#working on at the time.
setwd("~/Dropbox/web/junruidi.github.io/")
#render your sweet site.
rmarkdown::render_site()
# git add -A
# git commit -m "2nd commit"
# git push origin master
#Set our working directory.
#This helps avoid confusion if our working directory is
#not our site because of other projects we were
#working on at the time.
setwd("~/Dropbox/web/junruidi.github.io/")
#render your sweet site.
rmarkdown::render_site()
# git add -A
# git commit -m "2nd commit"
# git push origin master
#Set our working directory.
#This helps avoid confusion if our working directory is
#not our site because of other projects we were
#working on at the time.
setwd("D:/Dropbox/web/junruidi.github.io/")
#render your sweet site.
rmarkdown::render_site()
# git add -A
# git commit -m "2nd commit"
# git push origin master
