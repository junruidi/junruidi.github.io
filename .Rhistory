def_X = X - lambda_hat * theta_hat %o% theta_hat %o% theta_hat
result = list("theta_hat" = theta_hat, "lambda_hat" = lambda_hat, "def_X" = def_X)
return(result)
}
X = Yn
p = dim(X)[1]
eigenv = list()
eigenl = NULL
for( m in 1:p){
result.m = Est_PI(X = X, L=10, N=10)
eigenv[[m]] = result.m$theta_hat
eigenl = c(eigenl, result.m$lambda_hat)
X = result.m$def_X
}
rm(list = ls())
library(pracma)
X = rortho(10)
v1 = X[,1]
v2 = X[,2]
v3 = X[,3]
v4 = X[,4]
v5 = X[,5]
v6 = X[,6]
v7 = X[,7]
v8 = X[,8]
v9 = X[,9]
v10 = X[,10]
l1 = 10
l2 = 9
l3 = 8
l4 = 7
l5 = 6
l6 = 5
l7 = 4
l8 = 3
l9 = 2
l10 = 1
Y = l1 * v1 %o% v1 %o% v1 + l2 * v2 %o% v2 %o% v2 + l3 * v3 %o% v3 %o% v3 + l4 * v4 %o% v4 %o% v4 +
l5 * v5 %o% v5 %o% v5 + l6 * v6 %o% v6 %o% v6 + l7 * v7 %o% v7 %o% v7 + l8 * v8 %o% v8 %o% v8 +
l9 * v9 %o% v9 %o% v9 + l10 * v10 %o% v10 %o% v10
mat.noise = matrix(rnorm(100,mean = 0.001,sd = 0.01),10)
m1 = mat.noise[,1]
m2 = mat.noise[,2]
m3 = mat.noise[,3]
m4 = mat.noise[,4]
m5 = mat.noise[,5]
m6 = mat.noise[,6]
m7 = mat.noise[,7]
m8 = mat.noise[,8]
m9 = mat.noise[,9]
m10 = mat.noise[,10]
t.noise = m1 %o% m1 %o% m1 + m2 %o% m2 %o% m2 + m3 %o% m3 %o% m3 + m4 %o% m4 %o% m4 +
m5 %o% m5 %o% m5 + m6 %o% m6 %o% m6 + m7 %o% m7 %o% m7 + m8 %o% m8 %o% m8 + m9 %o% m9 %o% m9 +
m10 %o% m10 %o% m10
Yn = Y+t.noise
#function to calculate quadratic operator e.g. T(I,\theta,\theta)
Xvv = function(X,v){
dimX = dim(X)[1]
z = NULL
for(i in 1:dimX){
aa = 0
for(j in 1:dimX){
for(l in 1:dimX){
aa = aa + X[j,l,i] * v[j] * v[l]
}
}
z = c(z,aa)
}
return(z)
}
#function to calcaulte multilinear form e (dot product between tenor T and vector \theta).g. T(\theta,\theta,\theta)
Xvvv = function(X,v){
lm  = dim(X)[1]
zz = 0
for(j3 in 1:lm){
for(j2 in 1:lm){
for(j1 in 1:lm){
zz = zz +  X[j1, j2, j3] * v[j1] * v[j2] * v[j3]
}
}
}
return(zz)
}
#inner power iteration update, use (7) in Anandkumar paper
power_itr = function(theta, X,N){
for(i in 1:N){
next_itr = Xvv(X, v = theta)
theta = next_itr/sqrt(sum(next_itr^2))
}
return(theta)
}
#select the best theta, lambda, and deflate the original tensor
Est_PI = function(X, L=10, N=10){
p = dim(X)[1]
theta_list = list()
for ( t in 1:L){
vc = rnorm(p)
theta_0 = vc/sqrt(sum(vc^2))
theta_list[[t]] = power_itr(theta = theta_0, X=X, N=N)
}
lambda_list = NULL
for(t in 1:L){
lambda_t = Xvvv(X = X, v = theta_list[[t]])
lambda_list = c(lambda_list,lambda_t)
}
ind = which.max(lambda_list)
theta_hat = theta_list[[ind]]
lambda_hat = lambda_list[[ind]]
def_X = X - lambda_hat * theta_hat %o% theta_hat %o% theta_hat
result = list("theta_hat" = theta_hat, "lambda_hat" = lambda_hat, "def_X" = def_X)
return(result)
}
X = Yn
p = dim(X)[1]
eigenv = list()
eigenl = NULL
for( m in 1:p){
result.m = Est_PI(X = X, L=10, N=10)
eigenv[[m]] = result.m$theta_hat
eigenl = c(eigenl, result.m$lambda_hat)
X = result.m$def_X
}
eigenl
#some simulations
rm(list = ls())
library(pracma)
X = rortho(10)
v1 = X[,1]
v2 = X[,2]
v3 = X[,3]
v4 = X[,4]
v5 = X[,5]
v6 = X[,6]
v7 = X[,7]
v8 = X[,8]
v9 = X[,9]
v10 = X[,10]
l1 = 10
l2 = 9
l3 = 8
l4 = 7
l5 = 6
l6 = 5
l7 = 4
l8 = 3
l9 = 2
l10 = 1
Y = l1 * v1 %o% v1 %o% v1 + l2 * v2 %o% v2 %o% v2 + l3 * v3 %o% v3 %o% v3 + l4 * v4 %o% v4 %o% v4 +
l5 * v5 %o% v5 %o% v5 + l6 * v6 %o% v6 %o% v6 + l7 * v7 %o% v7 %o% v7 + l8 * v8 %o% v8 %o% v8 +
l9 * v9 %o% v9 %o% v9 + l10 * v10 %o% v10 %o% v10
mat.noise = matrix(rnorm(100,mean = 0.1,sd = 0.1),10)
m1 = mat.noise[,1]
m2 = mat.noise[,2]
m3 = mat.noise[,3]
m4 = mat.noise[,4]
m5 = mat.noise[,5]
m6 = mat.noise[,6]
m7 = mat.noise[,7]
m8 = mat.noise[,8]
m9 = mat.noise[,9]
m10 = mat.noise[,10]
t.noise = m1 %o% m1 %o% m1 + m2 %o% m2 %o% m2 + m3 %o% m3 %o% m3 + m4 %o% m4 %o% m4 +
m5 %o% m5 %o% m5 + m6 %o% m6 %o% m6 + m7 %o% m7 %o% m7 + m8 %o% m8 %o% m8 + m9 %o% m9 %o% m9 +
m10 %o% m10 %o% m10
Yn = Y+t.noise
#function to calculate quadratic operator e.g. T(I,\theta,\theta)
Xvv = function(X,v){
dimX = dim(X)[1]
z = NULL
for(i in 1:dimX){
aa = 0
for(j in 1:dimX){
for(l in 1:dimX){
aa = aa + X[j,l,i] * v[j] * v[l]
}
}
z = c(z,aa)
}
return(z)
}
#function to calcaulte multilinear form e (dot product between tenor T and vector \theta).g. T(\theta,\theta,\theta)
Xvvv = function(X,v){
lm  = dim(X)[1]
zz = 0
for(j3 in 1:lm){
for(j2 in 1:lm){
for(j1 in 1:lm){
zz = zz +  X[j1, j2, j3] * v[j1] * v[j2] * v[j3]
}
}
}
return(zz)
}
#inner power iteration update, use (7) in Anandkumar paper
power_itr = function(theta, X,N){
for(i in 1:N){
next_itr = Xvv(X, v = theta)
theta = next_itr/sqrt(sum(next_itr^2))
}
return(theta)
}
#select the best theta, lambda, and deflate the original tensor
Est_PI = function(X, L=10, N=10){
p = dim(X)[1]
theta_list = list()
for ( t in 1:L){
vc = rnorm(p)
theta_0 = vc/sqrt(sum(vc^2))
theta_list[[t]] = power_itr(theta = theta_0, X=X, N=N)
}
lambda_list = NULL
for(t in 1:L){
lambda_t = Xvvv(X = X, v = theta_list[[t]])
lambda_list = c(lambda_list,lambda_t)
}
ind = which.max(lambda_list)
theta_hat = theta_list[[ind]]
lambda_hat = lambda_list[[ind]]
def_X = X - lambda_hat * theta_hat %o% theta_hat %o% theta_hat
result = list("theta_hat" = theta_hat, "lambda_hat" = lambda_hat, "def_X" = def_X)
return(result)
}
X = Yn
p = dim(X)[1]
eigenv = list()
eigenl = NULL
for( m in 1:p){
result.m = Est_PI(X = X, L=10, N=10)
eigenv[[m]] = result.m$theta_hat
eigenl = c(eigenl, result.m$lambda_hat)
X = result.m$def_X
}
eigenl
sum(eigenv[[1]]*eigenv[[2]])
sum(eigenv[[1]]*eigenv[[3]])
sum(eigenv[[1]]*eigenv[[5]])
#some simulations
rm(list = ls())
library(pracma)
X = rortho(10)
v1 = X[,1]
v2 = X[,2]
v3 = X[,3]
v4 = X[,4]
v5 = X[,5]
v6 = X[,6]
v7 = X[,7]
v8 = X[,8]
v9 = X[,9]
v10 = X[,10]
l1 = 10
l2 = 9
l3 = 8
l4 = 7
l5 = 6
l6 = 5
l7 = 4
l8 = 3
l9 = 2
l10 = 1
Y = l1 * v1 %o% v1 %o% v1 + l2 * v2 %o% v2 %o% v2 + l3 * v3 %o% v3 %o% v3 + l4 * v4 %o% v4 %o% v4 +
l5 * v5 %o% v5 %o% v5 + l6 * v6 %o% v6 %o% v6 + l7 * v7 %o% v7 %o% v7 + l8 * v8 %o% v8 %o% v8 +
l9 * v9 %o% v9 %o% v9 + l10 * v10 %o% v10 %o% v10
mat.noise = matrix(rnorm(100,mean = 0.1,sd = 0.01),10)
m1 = mat.noise[,1]
m2 = mat.noise[,2]
m3 = mat.noise[,3]
m4 = mat.noise[,4]
m5 = mat.noise[,5]
m6 = mat.noise[,6]
m7 = mat.noise[,7]
m8 = mat.noise[,8]
m9 = mat.noise[,9]
m10 = mat.noise[,10]
t.noise = m1 %o% m1 %o% m1 + m2 %o% m2 %o% m2 + m3 %o% m3 %o% m3 + m4 %o% m4 %o% m4 +
m5 %o% m5 %o% m5 + m6 %o% m6 %o% m6 + m7 %o% m7 %o% m7 + m8 %o% m8 %o% m8 + m9 %o% m9 %o% m9 +
m10 %o% m10 %o% m10
Yn = Y+t.noise
Xvv = function(X,v){
dimX = dim(X)[1]
z = NULL
for(i in 1:dimX){
aa = 0
for(j in 1:dimX){
for(l in 1:dimX){
aa = aa + X[j,l,i] * v[j] * v[l]
}
}
z = c(z,aa)
}
return(z)
}
#function to calcaulte multilinear form e (dot product between tenor T and vector \theta).g. T(\theta,\theta,\theta)
Xvvv = function(X,v){
lm  = dim(X)[1]
zz = 0
for(j3 in 1:lm){
for(j2 in 1:lm){
for(j1 in 1:lm){
zz = zz +  X[j1, j2, j3] * v[j1] * v[j2] * v[j3]
}
}
}
return(zz)
}
#inner power iteration update, use (7) in Anandkumar paper
power_itr = function(theta, X,N){
for(i in 1:N){
next_itr = Xvv(X, v = theta)
theta = next_itr/sqrt(sum(next_itr^2))
}
return(theta)
}
#select the best theta, lambda, and deflate the original tensor
Est_PI = function(X, L=10, N=10){
p = dim(X)[1]
theta_list = list()
for ( t in 1:L){
vc = rnorm(p)
theta_0 = vc/sqrt(sum(vc^2))
theta_list[[t]] = power_itr(theta = theta_0, X=X, N=N)
}
lambda_list = NULL
for(t in 1:L){
lambda_t = Xvvv(X = X, v = theta_list[[t]])
lambda_list = c(lambda_list,lambda_t)
}
ind = which.max(lambda_list)
theta_hat = theta_list[[ind]]
lambda_hat = lambda_list[[ind]]
def_X = X - lambda_hat * theta_hat %o% theta_hat %o% theta_hat
result = list("theta_hat" = theta_hat, "lambda_hat" = lambda_hat, "def_X" = def_X)
return(result)
}
X = Yn
p = dim(X)[1]
eigenv = list()
eigenl = NULL
for( m in 1:p){
result.m = Est_PI(X = X, L=10, N=10)
eigenv[[m]] = result.m$theta_hat
eigenl = c(eigenl, result.m$lambda_hat)
X = result.m$def_X
}
eigenl
eigenv
sum(eigenv[[1]]*eigenv[[2]])
sum(eigenv[[1]]*eigenv[[3]])
rm(list = ls())
load("~/Dropbox/Junrui Di/MAMC/tensor decompostion analysis/data/analysis.rda")
#function to calculate quadratic operator e.g. T(I,\theta,\theta)
Xvv = function(X,v){
dimX = dim(X)[1]
z = NULL
for(i in 1:dimX){
aa = 0
for(j in 1:dimX){
for(l in 1:dimX){
aa = aa + X[j,l,i] * v[j] * v[l]
}
}
z = c(z,aa)
}
return(z)
}
#function to calcaulte multilinear form e (dot product between tenor T and vector \theta).g. T(\theta,\theta,\theta)
Xvvv = function(X,v){
lm  = dim(X)[1]
zz = 0
for(j3 in 1:lm){
for(j2 in 1:lm){
for(j1 in 1:lm){
zz = zz +  X[j1, j2, j3] * v[j1] * v[j2] * v[j3]
}
}
}
return(zz)
}
#inner power iteration update, use (7) in Anandkumar paper
power_itr = function(theta, X,N){
for(i in 1:N){
next_itr = Xvv(X, v = theta)
theta = next_itr/sqrt(sum(next_itr^2))
}
return(theta)
}
#select the best theta, lambda, and deflate the original tensor
Est_PI = function(X, L=10, N=10){
p = dim(X)[1]
theta_list = list()
for ( t in 1:L){
vc = rnorm(p)
theta_0 = vc/sqrt(sum(vc^2))
theta_list[[t]] = power_itr(theta = theta_0, X=X, N=N)
}
lambda_list = NULL
for(t in 1:L){
lambda_t = Xvvv(X = X, v = theta_list[[t]])
lambda_list = c(lambda_list,lambda_t)
}
ind = which.max(lambda_list)
theta_hat = theta_list[[ind]]
lambda_hat = lambda_list[[ind]]
def_X = X - lambda_hat * theta_hat %o% theta_hat %o% theta_hat
result = list("theta_hat" = theta_hat, "lambda_hat" = lambda_hat, "def_X" = def_X)
return(result)
}
X = X3
p = dim(X)[1]
eigenv = list()
eigenl = NULL
for( m in 1:p){
result.m = Est_PI(X = X, L=10, N=10)
eigenv[[m]] = result.m$theta_hat
eigenl = c(eigenl, result.m$lambda_hat)
X = result.m$def_X
}
eigenl
eigenv
sum(eigenv[[1]]*eigenv[[2]])
sum(eigenv[[1]]*eigenv[[3]])
sum(eigenv[[1]]*eigenv[[4]])
sum(eigenv[[1]]*eigenv[[5]])
sum(eigenv[[1]]*eigenv[[6]])
sum(eigenv[[1]]*eigenv[[7]])
sum(eigenv[[1]]*eigenv[[8]])
sum(eigenv[[1]]*eigenv[[9]])
sum(eigenv[[1]]*eigenv[[10]])
sum(eigenv[[1]]*eigenv[[11]])
sum(eigenv[[1]]*eigenv[[12]])
sum(eigenv[[1]]*eigenv[[13]])
sum(eigenv[[1]]*eigenv[[14]])
sum(eigenv[[1]]*eigenv[[15]])
sum(eigenv[[1]]*eigenv[[16]])
sum(eigenv[[1]]*eigenv[[17]])
sum(eigenv[[1]]*eigenv[[18]])
sum(eigenv[[1]]*eigenv[[19]])
sum(eigenv[[1]]*eigenv[[20]])
sum(eigenv[[1]]*eigenv[[24]])
sum(eigenv[[1]]*eigenv[[25]])
sum(eigenv[[2]]*eigenv[[25]])
sum(eigenv[[2]]*eigenv[[24]])
sum(eigenv[[3]]*eigenv[[24]])
sum(eigenv[[4]]*eigenv[[24]])
#Set our working directory.
#This helps avoid confusion if our working directory is
#not our site because of other projects we were
#working on at the time.
setwd("~/Dropbox/web/junruidi.github.io/")
#render your sweet site.
rmarkdown::render_site()
# git add -A
# git commit -m "2nd commit"
#Set our working directory.
#This helps avoid confusion if our working directory is
#not our site because of other projects we were
#working on at the time.
setwd("~/Dropbox/web/junruidi.github.io/")
#render your sweet site.
rmarkdown::render_site()
#Set our working directory.
#This helps avoid confusion if our working directory is
#not our site because of other projects we were
#working on at the time.
setwd("~/Dropbox/web/junruidi.github.io/")
#render your sweet site.
rmarkdown::render_site()
# git add -A
# git commit -m "2nd commit"
# git push origin master
#Set our working directory.
#This helps avoid confusion if our working directory is
#not our site because of other projects we were
#working on at the time.
setwd("~/Dropbox/web/junruidi.github.io/")
#render your sweet site.
rmarkdown::render_site()
# git add -A
# git commit -m "2nd commit"
# git push origin master
View(Y)
rm(list = ls())
library(pracma)
X = rortho(10)
v1 = X[,1]
v2 = X[,2]
v3 = X[,3]
v4 = X[,4]
v5 = X[,5]
v6 = X[,6]
v7 = X[,7]
v8 = X[,8]
v9 = X[,9]
v10 = X[,10]
l1 = 10
l2 = 9
l3 = 8
l4 = 7
l5 = 6
l6 = 5
l7 = 4
l8 = 3
l9 = 2
l10 = 1
Y = l1 * v1 %o% v1 %o% v1 + l2 * v2 %o% v2 %o% v2 + l3 * v3 %o% v3 %o% v3 + l4 * v4 %o% v4 %o% v4 +
l5 * v5 %o% v5 %o% v5 + l6 * v6 %o% v6 %o% v6 + l7 * v7 %o% v7 %o% v7 + l8 * v8 %o% v8 %o% v8 +
l9 * v9 %o% v9 %o% v9 + l10 * v10 %o% v10 %o% v10
Y[1,2,1]
Y[1,1,2]
Y[2,1,2]
Y[2,1,1]
install.packages(c("expm", "XML"))
